{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI7Tre7x6ArB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myfile = '/content/drive/MyDrive/Colab Notebooks/Sentence_Auto_Completion_Using_NLP/holmes.txt'\n",
        "\n",
        "with open(myfile, 'r', encoding='utf-8') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "7HGwl5q70Zhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "id": "Pc8t-iLy6R_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e096375-c951-4907-ab62-a1b89056e46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236110709"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = text[:1000000]"
      ],
      "metadata": {
        "id": "NpqX2zFM6R8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # Remove non-alphanumeric characters except spaces\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()  # Strip leading and trailing whitespace\n",
        "\n",
        "def preprocessed_text(text):\n",
        "    sentences = text.split('\\n')\n",
        "    cleaned_sentences = [clean_text(sentence) for sentence in sentences if len(sentence.strip()) > 0]\n",
        "    tokenize = []\n",
        "    for sentences in cleaned_sentences:\n",
        "      sentences = sentences.lower()\n",
        "      tokenize.append(sentences)\n",
        "    return tokenize"
      ],
      "metadata": {
        "id": "eZrj0EqI6RWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_data = preprocessed_text(data)"
      ],
      "metadata": {
        "id": "ETW0y7mt6RTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*OOV Token* => Is used for unknown words in trainning data."
      ],
      "metadata": {
        "id": "FzZTKolQDpol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token = '<OOV>')\n",
        "tokenizer.fit_on_texts(tokenize_data)"
      ],
      "metadata": {
        "id": "ceuJUNPLC0ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_len = len(tokenizer.word_counts)"
      ],
      "metadata": {
        "id": "9R9-DlpUC0dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_gram_sequence = []\n",
        "for line in tokenize_data:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram = token_list[: i+1]\n",
        "    n_gram_sequence.append(n_gram)"
      ],
      "metadata": {
        "id": "S2o8rEb4C0XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_gram_sequence"
      ],
      "metadata": {
        "id": "tejSQ5bs6RQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding and List Comprehension"
      ],
      "metadata": {
        "id": "75s3w1viMcLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in n_gram_sequence])\n",
        "pad_sequences_data = np.array(pad_sequences(n_gram_sequence, maxlen = max_len, padding= 'pre'))"
      ],
      "metadata": {
        "id": "gQ0f2Qtt6RN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_sequences_data"
      ],
      "metadata": {
        "id": "yQopqpP86RKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e66ced9-5c75-4ac2-89b5-9af98d0670fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,  209, 1814],\n",
              "       [   0,    0,    0, ...,  209, 1814,  197],\n",
              "       [   0,    0,    0, ..., 1814,  197,    5],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    6,  730,   69],\n",
              "       [   0,    0,    0, ...,  730,   69,   49],\n",
              "       [   0,    0,    0, ...,   69,   49,   21]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad_sequences_data.shape"
      ],
      "metadata": {
        "id": "Df2viP3V6RAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c96d66-29e4-4bae-bec1-ea33cdd9daf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156818, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pad_sequences_data[:,:-1]\n",
        "y_train = pad_sequences_data[:,-1]"
      ],
      "metadata": {
        "id": "C7UxwZMvTHct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRwdzKOTMbF",
        "outputId": "390066c0-9532-42a1-f6b3-7ae9a3bb4b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    0,  209],\n",
              "       [   0,    0,    0, ...,    0,  209, 1814],\n",
              "       [   0,    0,    0, ...,  209, 1814,  197],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 1207,    6,  730],\n",
              "       [   0,    0,    0, ...,    6,  730,   69],\n",
              "       [   0,    0,    0, ...,  730,   69,   49]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVN--na0TQae",
        "outputId": "451d87be-60e1-47e7-9cc7-c3ae51425f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1814,  197,    5, ...,   69,   49,   21], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, labels = x_train, y_train"
      ],
      "metadata": {
        "id": "lS2P0acqPvNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_categorical_safe(y, num_classes):\n",
        "    y = np.array(y, dtype='int')\n",
        "\n",
        "    if np.any(y < 0):\n",
        "        raise ValueError(\"Negative values found in `y` after subtracting 1\")\n",
        "\n",
        "    if np.any(y >= num_classes):\n",
        "        raise ValueError(f\"Found an index in `y` that is out of bounds for the array size of {num_classes}\")\n",
        "\n",
        "    return tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "try:\n",
        "    categorical_labels = to_categorical_safe(pad_sequences_data, tokenizer_len)\n",
        "    print(categorical_labels)\n",
        "except ValueError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4kfsKBkUB-y",
        "outputId": "d0a3e589-f968-4751-beae-85400ad382b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found an index in `y` that is out of bounds for the array size of 9461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.to_categorical(labels-1, num_classes= tokenizer_len)"
      ],
      "metadata": {
        "id": "Z-7BjxIbP0PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBWX8QeRQFCz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}